{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_quant_params(filename):\n",
    "    \"\"\"\n",
    "    从文件名解析量化参数\n",
    "    规则：\n",
    "    - 文件名开头连续数字部分长度 >=3:\n",
    "      长度3: 301 → q_total=3, q_int=0\n",
    "      长度4: 1001 → q_total=10, q_int=0\n",
    "      长度5: 19121 → q_total=19, q_int=12\n",
    "    - 其他情况视为无效格式\n",
    "    \"\"\"\n",
    "    stem = Path(filename).stem\n",
    "    num_part = re.match(r\"^(\\d+)\", stem).group(1) if re.match(r\"^\\d+\", stem) else \"\"\n",
    "    \n",
    "    q_total = 0\n",
    "    q_int = 0\n",
    "    \n",
    "    # 参数解析逻辑\n",
    "    if len(num_part) >= 3:\n",
    "        # 总位宽解析\n",
    "        if len(num_part) == 3:\n",
    "            q_total = int(num_part[0])\n",
    "            q_int = int(num_part[1])\n",
    "        elif len(num_part) == 4:\n",
    "            q_total = int(num_part[:2])\n",
    "            q_int = int(num_part[2])\n",
    "        elif len(num_part) >= 5:  # 处理5位及以上的情况\n",
    "            q_total = int(num_part[:2])\n",
    "            q_int = int(num_part[2:4])\n",
    "    else:\n",
    "        raise ValueError(f\"文件名数字部分不足3位: {filename}\")\n",
    "    \n",
    "    return q_total, q_int\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"从文件名解析所有参数\"\"\"\n",
    "    stem = Path(filename).stem\n",
    "    \n",
    "    # 初始化默认值\n",
    "    quant_total_bits = 0\n",
    "    quant_int_bits = 0\n",
    "    initial_step = 0.0\n",
    "    final_step = 0.0\n",
    "\n",
    "    # 解析量化参数\n",
    "    quant_pattern = r\"^(\\d+?)(?=_|$)\"  # 匹配开头的数字部分\n",
    "    quant_match = re.match(quant_pattern, stem)\n",
    "    if quant_match:\n",
    "        quant_total_bits, quant_int_bits = parse_quant_params(filename)\n",
    "    \n",
    "    # 解析剪枝参数\n",
    "    prune_pattern = r\"_i(\\d{1,3})|_f(\\d{1,3})\"\n",
    "    prune_matches = re.finditer(prune_pattern, stem)\n",
    "    \n",
    "    for match in prune_matches:\n",
    "        if match.group(1):  # initial_step\n",
    "            i_val = match.group(1).lstrip('0') or '0'\n",
    "            initial_step = round(float(i_val)/100, 2)\n",
    "        elif match.group(2):  # final_step\n",
    "            f_val = match.group(2).lstrip('0') or '0'\n",
    "            final_step = round(float(f_val)/100, 2)\n",
    "\n",
    "    return quant_total_bits, quant_int_bits, initial_step, final_step\n",
    "\n",
    "def parse_python_acc(content):\n",
    "    \"\"\"解析Python模型准确率\"\"\"\n",
    "    first_line = content.split('\\n')[0]\n",
    "    acc_match = re.search(r\"python模型准确率:\\s*([\\d.]+)%\", first_line)\n",
    "    return float(acc_match.group(1)) if acc_match else 0.0\n",
    "\n",
    "def parse_file(file_path):\n",
    "    \"\"\"主解析函数\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # 自动解析参数\n",
    "        q_total, q_int, prune_init, prune_final = parse_filename(file_path)\n",
    "        python_acc = parse_python_acc(content)\n",
    "        \n",
    "        # 解析精度映射表\n",
    "        acc_pattern = r\"fixed<(\\d+),(\\d+)>: ([\\d.]+)%\"\n",
    "        accuracy_map = {(w, i): acc for w, i, acc in re.findall(acc_pattern, content)}\n",
    "        \n",
    "        # 解析硬件配置\n",
    "        pattern = r\"文件路径: fixed{(\\d+)_(\\d+)}.*?复用系数: (\\d+).*?资源占用: ({.*?}).*?模型延迟: ([\\d.]+)\\s*([mu]?s)\"\n",
    "        matches = re.findall(pattern, content, re.DOTALL)\n",
    "        \n",
    "        rows = []\n",
    "        for match in matches:\n",
    "            hls_total, hls_int, reuse_factor, resources_str, latency_val, latency_unit = match\n",
    "            \n",
    "            # 处理延迟单位\n",
    "            try:\n",
    "                latency = float(latency_val) * 8  # Vitis综合以200MHz计算延迟\n",
    "                if latency_unit.lower() == 'ms':\n",
    "                    latency *= 1000\n",
    "                elif latency_unit.lower() == 's':\n",
    "                    latency *= 1e6\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "            # 处理资源字段\n",
    "            try:\n",
    "                resources = json.loads(resources_str.replace(\"'\", \"\\\"\"))\n",
    "                resources = {k: int(float(v)) for k, v in resources.items()}\n",
    "            except:\n",
    "                resources = {'BRAM_18K': 0, 'DSP': 0, 'FF': 0, 'LUT': 0}\n",
    "                \n",
    "            # 构建记录\n",
    "            rows.append({\n",
    "                \"量化总位宽\": q_total,\n",
    "                \"量化整数位宽\": q_int,\n",
    "                \"hls4ml总位宽\": int(hls_total),\n",
    "                \"hls4ml整数位宽\": int(hls_int),\n",
    "                \"Reuse Factor\": int(reuse_factor),\n",
    "                \"剪枝inital step\": prune_init,\n",
    "                \"剪枝final step\": prune_final,\n",
    "                \"python模型准确率\": python_acc / 100,  # 存储为小数\n",
    "                \"hls4ml模型准确率\": float(accuracy_map.get((hls_total, hls_int), 0)) / 100,\n",
    "                \"BRAM占用率\": resources.get(\"BRAM_18K\", 0),\n",
    "                \"DSP占用率\": resources.get(\"DSP\", 0),\n",
    "                \"FF占用率\": resources.get(\"FF\", 0),\n",
    "                \"LUT占用率\": resources.get(\"LUT\", 0),\n",
    "                \"延迟(us)\": round(latency, 3)\n",
    "            })\n",
    "            \n",
    "        return pd.DataFrame(rows) if not pd.DataFrame(rows).empty else None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"解析错误: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def append_to_excel(new_df, filename):\n",
    "    \"\"\"改进后的数据追加函数\"\"\"\n",
    "    try:\n",
    "        col_formats = {\n",
    "            '量化总位宽': '0',\n",
    "            '量化整数位宽': '0',\n",
    "            'hls4ml总位宽': '0',\n",
    "            'hls4ml整数位宽': '0',\n",
    "            'Reuse Factor': '0',\n",
    "            'BRAM占用率': '0',\n",
    "            'DSP占用率': '0',\n",
    "            'FF占用率': '0',\n",
    "            'LUT占用率': '0',\n",
    "            '延迟(us)': '0.000',\n",
    "            'python模型准确率': '0.00%',\n",
    "            'hls4ml模型准确率': '0.00%',\n",
    "            '剪枝inital step': '0.00',\n",
    "            '剪枝final step': '0.00'\n",
    "        }\n",
    "\n",
    "        # 检查文件是否存在\n",
    "        file_exists = Path(filename).exists()\n",
    "        \n",
    "        # 如果文件存在，直接报错\n",
    "        if file_exists:\n",
    "            raise FileExistsError(f\"文件 {filename} 已存在，请手动删除后再运行\")\n",
    "\n",
    "        # 始终新建文件（因为不允许追加）\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "            # 写入数据并包含表头\n",
    "            new_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "            \n",
    "            # 应用格式\n",
    "            sheet = writer.sheets['Sheet1']\n",
    "            for col, fmt in col_formats.items():\n",
    "                col_idx = new_df.columns.get_loc(col)\n",
    "                for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, \n",
    "                                        min_col=col_idx+1, max_col=col_idx+1):\n",
    "                    for cell in row:\n",
    "                        cell.number_format = fmt\n",
    "        \n",
    "        print(f\"数据已保存到 {filename}\")\n",
    "        return True\n",
    "    \n",
    "    except FileExistsError as fee:\n",
    "        print(f\"错误：{str(fee)}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"保存失败: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def find_yaml_files(directory):\n",
    "    \"\"\"查找目录及其子目录下所有YAML文件\"\"\"\n",
    "    yaml_files = []\n",
    "    path = Path(directory)\n",
    "    \n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"目录 {directory} 不存在\")\n",
    "    \n",
    "    # 递归查找所有.yaml和.yml文件\n",
    "    for file_path in path.rglob(\"*.yaml\"):\n",
    "        yaml_files.append(file_path)\n",
    "    for file_path in path.rglob(\"*.yml\"):\n",
    "        yaml_files.append(file_path)\n",
    "    \n",
    "    return sorted(yaml_files)\n",
    "\n",
    "def process_folder(input_dir, output_file):\n",
    "    \"\"\"改进后的文件夹处理函数\"\"\"\n",
    "    try:\n",
    "        yaml_files = find_yaml_files(input_dir)\n",
    "        if not yaml_files:\n",
    "            print(f\"在 {input_dir} 中未找到YAML文件\")\n",
    "            return\n",
    "\n",
    "        print(f\"找到 {len(yaml_files)} 个YAML文件, 开始处理...\")\n",
    "        \n",
    "        # 收集所有数据\n",
    "        all_data = []\n",
    "        for i, file_path in enumerate(yaml_files, 1):\n",
    "            try:\n",
    "                print(f\"正在处理文件 ({i}/{len(yaml_files)}): {file_path.name}\")\n",
    "                df = parse_file(file_path)\n",
    "                if df is not None:\n",
    "                    all_data.append(df)\n",
    "                    print(f\"√ 成功处理：{file_path.name}\")\n",
    "                else:\n",
    "                    print(f\"× 跳过无效文件：{file_path.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"× 处理失败：{file_path.name}，错误：{str(e)}\")\n",
    "\n",
    "        if not all_data:\n",
    "            print(\"没有有效数据需要保存\")\n",
    "            return\n",
    "\n",
    "        # 合并所有数据\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # 一次性保存所有数据\n",
    "        success = append_to_excel(combined_df, output_file)\n",
    "        if success:\n",
    "            print(f\"\\n处理完成! 成功处理 {len(all_data)}/{len(yaml_files)} 个文件\")\n",
    "        else:\n",
    "            print(\"保存过程中发生错误\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理失败: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 37 个YAML文件, 开始处理...\n",
      "正在处理文件 (1/37): 1001.yaml\n",
      "√ 成功处理：1001.yaml\n",
      "正在处理文件 (2/37): 1001_i000_f020.yaml\n",
      "√ 成功处理：1001_i000_f020.yaml\n",
      "正在处理文件 (3/37): 1001_i000_f040.yaml\n",
      "√ 成功处理：1001_i000_f040.yaml\n",
      "正在处理文件 (4/37): 1001_i000_f060.yaml\n",
      "√ 成功处理：1001_i000_f060.yaml\n",
      "正在处理文件 (5/37): 1001_i000_f080.yaml\n",
      "√ 成功处理：1001_i000_f080.yaml\n",
      "正在处理文件 (6/37): 1001_i000_f090.yaml\n",
      "√ 成功处理：1001_i000_f090.yaml\n",
      "正在处理文件 (7/37): 1101.yaml\n",
      "√ 成功处理：1101.yaml\n",
      "正在处理文件 (8/37): 1201.yaml\n",
      "√ 成功处理：1201.yaml\n",
      "正在处理文件 (9/37): 1211.yaml\n",
      "√ 成功处理：1211.yaml\n",
      "正在处理文件 (10/37): 1221.yaml\n",
      "√ 成功处理：1221.yaml\n",
      "正在处理文件 (11/37): 1231.yaml\n",
      "√ 成功处理：1231.yaml\n",
      "正在处理文件 (12/37): 1241.yaml\n",
      "√ 成功处理：1241.yaml\n",
      "正在处理文件 (13/37): 1251.yaml\n",
      "√ 成功处理：1251.yaml\n",
      "正在处理文件 (14/37): 1261.yaml\n",
      "√ 成功处理：1261.yaml\n",
      "正在处理文件 (15/37): 1301_i010_f020.yaml\n",
      "√ 成功处理：1301_i010_f020.yaml\n",
      "正在处理文件 (16/37): 301.yaml\n",
      "√ 成功处理：301.yaml\n",
      "正在处理文件 (17/37): 301_i000_f030.yaml\n",
      "√ 成功处理：301_i000_f030.yaml\n",
      "正在处理文件 (18/37): 301_i015_f030.yaml\n",
      "√ 成功处理：301_i015_f030.yaml\n",
      "正在处理文件 (19/37): 401.yaml\n",
      "√ 成功处理：401.yaml\n",
      "正在处理文件 (20/37): 401_i000_f040.yaml\n",
      "√ 成功处理：401_i000_f040.yaml\n",
      "正在处理文件 (21/37): 401_i010_f040.yaml\n",
      "√ 成功处理：401_i010_f040.yaml\n",
      "正在处理文件 (22/37): 501.yaml\n",
      "√ 成功处理：501.yaml\n",
      "正在处理文件 (23/37): 601.yaml\n",
      "√ 成功处理：601.yaml\n",
      "正在处理文件 (24/37): 601_i000_f050.yaml\n",
      "√ 成功处理：601_i000_f050.yaml\n",
      "正在处理文件 (25/37): 601_i000_f080.yaml\n",
      "√ 成功处理：601_i000_f080.yaml\n",
      "正在处理文件 (26/37): 601_i020_f050.yaml\n",
      "√ 成功处理：601_i020_f050.yaml\n",
      "正在处理文件 (27/37): 601_i050_f080.yaml\n",
      "√ 成功处理：601_i050_f080.yaml\n",
      "正在处理文件 (28/37): 701.yaml\n",
      "√ 成功处理：701.yaml\n",
      "正在处理文件 (29/37): 701_i045_f070.yaml\n",
      "√ 成功处理：701_i045_f070.yaml\n",
      "正在处理文件 (30/37): 801.yaml\n",
      "√ 成功处理：801.yaml\n",
      "正在处理文件 (31/37): 801_i000_f025.yaml\n",
      "√ 成功处理：801_i000_f025.yaml\n",
      "正在处理文件 (32/37): 801_i020_f030.yaml\n",
      "√ 成功处理：801_i020_f030.yaml\n",
      "正在处理文件 (33/37): 901.yaml\n",
      "√ 成功处理：901.yaml\n",
      "正在处理文件 (34/37): 901_i000_f060.yaml\n",
      "√ 成功处理：901_i000_f060.yaml\n",
      "正在处理文件 (35/37): 901_i000_f080.yaml\n",
      "√ 成功处理：901_i000_f080.yaml\n",
      "正在处理文件 (36/37): 901_i030_f060.yaml\n",
      "√ 成功处理：901_i030_f060.yaml\n",
      "正在处理文件 (37/37): 901_i040_f080.yaml\n",
      "√ 成功处理：901_i040_f080.yaml\n",
      "数据已保存到 hls4ml_results.xlsx\n",
      "\n",
      "处理完成! 成功处理 37/37 个文件\n"
     ]
    }
   ],
   "source": [
    "# 配置参数\n",
    "INPUT_DIR   = \"results\"        # YAML文件存放目录\n",
    "OUTPUT_FILE = \"hls4ml_results.xlsx\"  # 输出文件名\n",
    "\n",
    "# 解析目录下的所有yaml\n",
    "process_folder(INPUT_DIR, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过滤后的文件已保存为 hls4ml_results_filtered.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel(\"hls4ml_results.xlsx\")\n",
    "\n",
    "# 过滤: 保留“Reuse Factor”列中值为1或者1000的行\n",
    "df_filtered = df[(df['Reuse Factor'] == 1) | (df['Reuse Factor'] == 1000)]\n",
    "# 将过滤后的数据保存到新的Excel文件中\n",
    "df_filtered.to_excel(\"hls4ml_results_filtered.xlsx\", index=False)\n",
    "\n",
    "print(\"过滤后的文件已保存为 hls4ml_results_filtered.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
