{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hls4ml.converters import convert_from_keras_model\n",
    "from hls4ml.utils import config_from_keras_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import plotting\n",
    "\n",
    "# 加载数据集\n",
    "def load_data():\n",
    "    train_data = sio.loadmat('train_32x32.mat')\n",
    "    test_data = sio.loadmat('test_32x32.mat')\n",
    "    X_train = np.transpose(train_data['X'], (3, 0, 1, 2))\n",
    "    y_train = train_data['y'].reshape(-1)\n",
    "    X_test = np.transpose(test_data['X'], (3, 0, 1, 2))\n",
    "    y_test = test_data['y'].reshape(-1)\n",
    "    y_train[y_train == 10] = 0\n",
    "    y_test[y_test == 10] = 0\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# 归一化数据\n",
    "def normalize_data(X_train, X_test):\n",
    "    X_train = X_train / 255.0\n",
    "    X_test  = X_test  / 255.0\n",
    "    return X_train, X_test\n",
    "\n",
    "# 转换为 one-hot 编码\n",
    "def one_hot_encode_labels(y_train, y_test):\n",
    "    y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "    y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "    return y_train_one_hot, y_test_one_hot\n",
    "\n",
    "# 加载数据\n",
    "X_train, y_train, X_test, y_test = load_data()\n",
    "X_train, X_test = normalize_data(X_train, X_test)\n",
    "y_train, y_test = one_hot_encode_labels(y_train, y_test)\n",
    "\n",
    "# 取得测试集的前10%(全部测试用时太久)\n",
    "num_samples = len(X_test) // 10\n",
    "X_test_subset = X_test[:num_samples]\n",
    "y_test_subset = y_test[:num_samples]\n",
    "\n",
    "# 可视化模型预测结果\n",
    "def plot_predictions(images, true_labels, predicted_labels, start=0):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(start, start + 25):\n",
    "        plt.subplot(5, 5, i - start + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        clipped_image = np.clip(images[i], 0, 1)  # 剪裁图像数据到合适的范围\n",
    "        plt.imshow(clipped_image)\n",
    "        true_label = true_labels[i]\n",
    "        predicted_label = predicted_labels[i]\n",
    "        color = 'blue' if true_label == predicted_label else 'red'\n",
    "        plt.xlabel(f\"True: {true_label}\\nPred: {predicted_label}\", color=color)\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# 保存数据到 .npy 文件\n",
    "def save_data(X_test, y_test):\n",
    "    np.save('X_test.npy', X_test)\n",
    "    np.save('y_test.npy', y_test)\n",
    "\n",
    "# 调用保存函数\n",
    "save_data(X_test_subset, y_test_subset)\n",
    "print(X_test_subset[0])\n",
    "print(\"--------------\")\n",
    "print(y_test_subset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, add, Flatten, BatchNormalization, Activation, MaxPooling2D\n",
    "from qkeras import QConv2D, QDense, QActivation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 定义量化位宽\n",
    "bit_width = 5\n",
    "integer_bits = 0\n",
    "quantization_params = 1\n",
    "quant_bits=f\"quantized_bits({bit_width}, {integer_bits}, {quantization_params})\"\n",
    "\n",
    "# 检查每层的可训练参数量\n",
    "def check_model_params(model, threshold=4096):\n",
    "    for layer in model.layers:\n",
    "        num_params = sum(tf.keras.backend.count_params(p) for p in layer.trainable_weights)\n",
    "        if num_params > threshold:\n",
    "            raise ValueError(f\"Layer {layer.name} has {num_params} parameters, which exceeds the threshold of {threshold}.\")\n",
    "        \n",
    "# 生成ResNet块\n",
    "def resnet_block(inputs, filters, kernel_size, quant_bits):\n",
    "    x = QConv2D(filters, kernel_size=kernel_size, padding='same',\n",
    "                kernel_quantizer=quant_bits, bias_quantizer=quant_bits)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = QActivation(activation=f'quantized_relu({bit_width},{integer_bits},{quantization_params})')(x)\n",
    "    return x\n",
    "\n",
    "# 生成ResNet模型\n",
    "def create_resnet(input_shape, num_classes, quant_bits):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_block(inputs, 10, (3, 3), quant_bits)  # 缩小filter数量\n",
    "    x = resnet_block(x, 10, (3, 3), quant_bits)\n",
    "    shortcut = QConv2D(10, kernel_size=(1, 1), padding='same', bias_quantizer=quant_bits)(inputs)  # 调整shortcut的形状\n",
    "    x = add([x, shortcut])  # 残差连接\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = QConv2D(4, (3,3),  kernel_quantizer=quant_bits, bias_quantizer=quant_bits)(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = QConv2D(4, (3,3),  kernel_quantizer=quant_bits, bias_quantizer=quant_bits)(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = QDense(num_classes, kernel_quantizer=quant_bits, bias_quantizer=quant_bits)(x)\n",
    "    outputs = Activation('softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "qmodel = create_resnet(X_train.shape[1:], 10, quant_bits)\n",
    "qmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "qmodel.summary()\n",
    "check_model_params(qmodel)\n",
    "\n",
    "# 训练模型\n",
    "qmodel.fit(X_train, y_train, epochs=25, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# 进行预测\n",
    "predictions = qmodel.predict(X_test)\n",
    "# 获取每个样本的预测类别\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f'模型在测试集上的准确率: {accuracy * 100:.2f}%')\n",
    "\n",
    "# 保存模型\n",
    "qmodel.save('model/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# 创建一个剪枝策略\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.00,\n",
    "        final_sparsity=0.40,\n",
    "        begin_step=0,\n",
    "        end_step=len(X_train) * 25 // 32)  # 30个epoch, batch_size为32\n",
    "}\n",
    "# 对模型进行剪枝\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(qmodel, **pruning_params)\n",
    "model_for_pruning.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 添加一个剪枝回调\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir='/tmp/logs')\n",
    "]\n",
    "# 训练剪枝后的模型\n",
    "model_for_pruning.fit(X_train, y_train, epochs=25, batch_size=32, validation_split=0.1, callbacks=callbacks)\n",
    "\n",
    "# 去掉剪枝部分，导出普通模型\n",
    "pmodel = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "pmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 再次进行预测和评估\n",
    "predictions = pmodel.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f'剪枝后模型在测试集上的准确率: {accuracy * 100:.2f}%')\n",
    "\n",
    "# 保存模型\n",
    "pmodel.save('model/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "# 加载模型\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "model = load_model('model/test.h5', custom_objects=co)\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f'模型在测试集上的准确率: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试CPU推理速度\n",
    "predictions = model.predict(X_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型转换为HLS格式\n",
    "config = config_from_keras_model(model, backend='VivadoAccelerator',\n",
    "                                 default_precision='fixed<13,6>',\n",
    "                                 #max_precision='fixed<32,16>',\n",
    "                                 granularity='model')\n",
    "config['Model']['ReuseFactor'] = 1000\n",
    "config['Model']['Strategy'] = 'Resource'  # Latency/Resource/Unrolled\n",
    "plotting.print_dict(config)\n",
    "\n",
    "hls_model = convert_from_keras_model(model, hls_config=config,\n",
    "                                     backend='VivadoAccelerator', io_type='io_stream',\n",
    "                                     output_dir='hls4ml_prj/test', board='pynq-z2')\n",
    "# 编译HLS模型\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 X_test 转换为连续的内存布局\n",
    "X_test_contiguous = np.ascontiguousarray(X_test_subset)\n",
    "# 计算准确率\n",
    "predictions = hls_model.predict(X_test_contiguous)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test_subset, axis=1)\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f'HLS模型的准确率: {accuracy * 100:.2f}%')\n",
    "# 可视化模型预测结果\n",
    "#plot_predictions(X_test_subset, y_test_subset, predicted_classes, start=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False, export=True, bitfile=True)\n",
    "#hls4ml.report.read_vivado_report('hls4ml_prj/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_power_values(file_path):\n",
    "    # 打开文件并读取第 32 至 45 行\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()[31:45] # 注意 Python 的索引是从 0 开始的，所以 32 行对应索引 31\n",
    "    \n",
    "    # 初始化返回值\n",
    "    total_on_chip_power = None\n",
    "    dynamic_power = None\n",
    "    device_static_power = None\n",
    "\n",
    "    # 遍历每一行，提取所需的值\n",
    "    for line in lines:\n",
    "        if 'Total On-Chip Power (W)' in line:\n",
    "            # 提取字符串并转为 float\n",
    "            total_on_chip_power = float(line.split('|')[2].strip())\n",
    "        elif 'Dynamic (W)' in line:\n",
    "            dynamic_power = float(line.split('|')[2].strip())\n",
    "        elif 'Device Static (W)' in line:\n",
    "            device_static_power = float(line.split('|')[2].strip())\n",
    "\n",
    "    return {\n",
    "        '芯片总功耗(W)': total_on_chip_power,\n",
    "        '动态功耗(W)': dynamic_power,\n",
    "        '静态功耗(W)': device_static_power\n",
    "    }\n",
    "\n",
    "# 示例调用\n",
    "file_path = 'hls4ml_prj/test/myproject_vivado_accelerator/project_1.runs/impl_1/design_1_wrapper_power_routed.rpt'\n",
    "power_values = extract_power_values(file_path)\n",
    "print(power_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_resource_utilization(file_path):\n",
    "    def extract_utilization(lines, start, end, targets):\n",
    "        results = {}\n",
    "        for line in lines[start:end]:\n",
    "            parts = [p.strip() for p in line.strip().split('|')]\n",
    "            if len(parts) >= 6 and parts[1] in targets:\n",
    "                # 处理百分比符号并转换为浮点数\n",
    "                util = parts[5].replace('%', '')\n",
    "                results[parts[1]] = float(util)\n",
    "        return results\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    # 确保索引从 0开始计算 (行号-1)\n",
    "    lut_ff = extract_utilization(content, 30, 44, ['Slice LUTs', 'Slice Registers'])\n",
    "    bram = extract_utilization(content, 100, 109, ['Block RAM Tile'])\n",
    "    dsp = extract_utilization(content, 115, 121, ['DSPs'])\n",
    "\n",
    "    return {\n",
    "        'LUT': lut_ff.get('Slice LUTs'),\n",
    "        'FF': lut_ff.get('Slice Registers'),\n",
    "        'BRAM': bram.get('Block RAM Tile'),\n",
    "        'DSP': dsp.get('DSPs')\n",
    "    }\n",
    "\n",
    "# 使用示例\n",
    "file_path = 'hls4ml_prj/test/myproject_vivado_accelerator/project_1.runs/impl_1/design_1_wrapper_utilization_placed.rpt'\n",
    "result = parse_resource_utilization(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_bit = \"hls4ml_prj/test/myproject_vivado_accelerator/project_1.runs/impl_1/design_1_wrapper.bit\"\n",
    "dest_bit = \"pynq-z2/hls4ml_nn.bit\"\n",
    "\n",
    "source_hwh = \"hls4ml_prj/test/myproject_vivado_accelerator/project_1.srcs/sources_1/bd/design_1/hw_handoff/design_1.hwh\"\n",
    "dest_hwh = \"pynq-z2/hls4ml_nn.hwh\"\n",
    "\n",
    "source_driver = \"hls4ml_prj/test/axi_stream_driver.py\"\n",
    "dest_driver = \"pynq-z2/axi_stream_driver.py\"\n",
    "\n",
    "# 如果目标文件夹不存在，则创建\n",
    "dest_dir = \"pynq-z2\"\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)\n",
    "    print(f\"已创建目标文件夹: {dest_dir}\")\n",
    "\n",
    "# 复制 .bit 文件并重命名\n",
    "try:\n",
    "    shutil.copy(source_bit, dest_bit)\n",
    "    print(f\"成功复制 '{source_bit}' 到 '{dest_bit}'\")\n",
    "except Exception as e:\n",
    "    print(f\"复制 '{source_bit}' 到 '{dest_bit}' 时出错: {e}\")\n",
    "\n",
    "# 复制 .hwh 文件并重命名\n",
    "try:\n",
    "    shutil.copy(source_hwh, dest_hwh)\n",
    "    print(f\"成功复制 '{source_hwh}' 到 '{dest_hwh}'\")\n",
    "except Exception as e:\n",
    "    print(f\"复制 '{source_hwh}' 到 '{dest_hwh}' 时出错: {e}\")\n",
    "\n",
    "# 复制 axi_stream_driver 到目标文件夹\n",
    "try:\n",
    "    shutil.copy(source_driver, dest_driver)\n",
    "    print(f\"成功复制 '{source_driver}' 到 '{dest_driver}'\")\n",
    "except Exception as e:\n",
    "    print(f\"复制 '{source_driver}' 到 '{dest_driver}' 时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预测结果 (从 y_hw.npy 文件)\n",
    "predictions = np.load(\"y_hw.npy\")\n",
    "# 提取预测类别\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test_subset, axis=1)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f\"硬件推理准确率: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
